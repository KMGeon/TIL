# 7. Spring Batch 파티셔닝 (Partitioning)

---

## 개요

Spring Batch 파티셔닝은 대용량 데이터를 효율적으로 처리하기 위해 단일 Step을 여러 개의 병렬 Step으로 분할하여 실행하는 기능입니다.
각 파티션은 독립적으로 실행되어 전체 처리 성능을 크게 향상시킬 수 있습니다.

## 파티셔닝 구성 요소

### 1. Master Step
- 파티션들을 관리하는 주 Step
- Slave Step들을 생성하고 관리
- 파티션별 실행 상태 모니터링

### 2. Slave Step  
- 실제 데이터 처리를 담당하는 Step
- 각 파티션의 독립적인 실행 단위
- 일반적인 Chunk 기반 처리 구조

### 3. Partitioner
- 데이터를 어떻게 분할할지 결정하는 인터페이스
- 각 파티션에 대한 ExecutionContext 생성
- 파티션별 매개변수 설정

### 4. PartitionHandler
- 파티션들의 실행을 관리
- 멀티스레드 또는 원격 실행 처리
- TaskExecutorPartitionHandler (멀티스레드)
- MessageChannelPartitionHandler (원격 실행)

## 파티셔닝 동작 원리

![파티셔닝 구조도](../../img/partitioning-diagram.png)

1. **파티션 생성**: Partitioner가 데이터를 논리적으로 분할
2. **파티션 실행**: PartitionHandler가 각 파티션을 병렬로 실행
3. **결과 집계**: 모든 파티션의 처리가 완료되면 Master Step에서 결과 취합

---

## JPA 버전 파티셔닝

### 기본 구성

```java
@Configuration
@EnableBatchProcessing
public class JpaPartitioningJobConfig {

    @Autowired
    private JobRepository jobRepository;
    
    @Autowired
    private PlatformTransactionManager transactionManager;
    
    @Autowired
    private EntityManagerFactory entityManagerFactory;
    
    private static final int CHUNK_SIZE = 100;
    private static final int POOL_SIZE = 5;

    @Bean
    public Job jpaPartitioningJob() {
        return new JobBuilder("jpaPartitioningJob", jobRepository)
                .start(masterStep())
                .build();
    }

    @Bean
    public Step masterStep() {
        return new StepBuilder("masterStep", jobRepository)
                .partitioner(slaveStep().getName(), partitioner())
                .step(slaveStep())
                .partitionHandler(partitionHandler())
                .build();
    }

    @Bean
    public Step slaveStep() {
        return new StepBuilder("slaveStep", jobRepository)
                .<Customer, Customer>chunk(CHUNK_SIZE, transactionManager)
                .reader(jpaItemReader(null, null))
                .processor(jpaItemProcessor())
                .writer(jpaItemWriter())
                .build();
    }

    @Bean
    public Partitioner partitioner() {
        return new JpaRangePartitioner();
    }

    @Bean
    public PartitionHandler partitionHandler() {
        TaskExecutorPartitionHandler handler = new TaskExecutorPartitionHandler();
        handler.setTaskExecutor(taskExecutor());
        handler.setStep(slaveStep());
        handler.setGridSize(POOL_SIZE);
        return handler;
    }

    @Bean
    public TaskExecutor taskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(POOL_SIZE);
        executor.setMaxPoolSize(POOL_SIZE);
        executor.setThreadNamePrefix("partition-thread-");
        executor.setWaitForTasksToCompleteOnShutdown(true);
        executor.initialize();
        return executor;
    }
}
```

### JPA Partitioner 구현

```java
public class JpaRangePartitioner implements Partitioner {

    @Autowired
    private EntityManagerFactory entityManagerFactory;

    @Override
    public Map<String, ExecutionContext> partition(int gridSize) {
        EntityManager entityManager = entityManagerFactory.createEntityManager();
        
        try {
            // 전체 레코드 수 조회
            Long totalCount = entityManager
                .createQuery("SELECT COUNT(c) FROM Customer c", Long.class)
                .getSingleResult();
            
            // 최소/최대 ID 조회
            Long minId = entityManager
                .createQuery("SELECT MIN(c.id) FROM Customer c", Long.class)
                .getSingleResult();
            
            Long maxId = entityManager
                .createQuery("SELECT MAX(c.id) FROM Customer c", Long.class)
                .getSingleResult();

            // 파티션별 범위 계산
            long rangeSize = (maxId - minId) / gridSize + 1;
            Map<String, ExecutionContext> result = new HashMap<>();

            for (int i = 0; i < gridSize; i++) {
                ExecutionContext context = new ExecutionContext();
                
                long startId = minId + (i * rangeSize);
                long endId = (i == gridSize - 1) ? maxId : startId + rangeSize - 1;
                
                context.putLong("startId", startId);
                context.putLong("endId", endId);
                
                result.put("partition" + i, context);
            }
            
            return result;
            
        } finally {
            entityManager.close();
        }
    }
}
```

### JPA ItemReader with Partitioning

```java
@Bean
@StepScope
public JpaPagingItemReader<Customer> jpaItemReader(
        @Value("#{stepExecutionContext[startId]}") Long startId,
        @Value("#{stepExecutionContext[endId]}") Long endId) {
    
    Map<String, Object> parameters = new HashMap<>();
    parameters.put("startId", startId);
    parameters.put("endId", endId);
    
    return new JpaPagingItemReaderBuilder<Customer>()
            .name("jpaItemReader")
            .entityManagerFactory(entityManagerFactory)
            .pageSize(CHUNK_SIZE)
            .queryString("SELECT c FROM Customer c WHERE c.id BETWEEN :startId AND :endId ORDER BY c.id")
            .parameterValues(parameters)
            .build();
}

@Bean
public ItemProcessor<Customer, Customer> jpaItemProcessor() {
    return customer -> {
        // 비즈니스 로직 처리
        customer.setProcessed(true);
        customer.setProcessedDate(LocalDateTime.now());
        return customer;
    };
}

@Bean
public JpaItemWriter<Customer> jpaItemWriter() {
    return new JpaItemWriterBuilder<Customer>()
            .entityManagerFactory(entityManagerFactory)
            .build();
}
```

---

## JDBC 버전 파티셔닝

### 기본 구성

```java
@Configuration
@EnableBatchProcessing
public class JdbcPartitioningJobConfig {

    @Autowired
    private JobRepository jobRepository;
    
    @Autowired
    private PlatformTransactionManager transactionManager;
    
    @Autowired
    private DataSource dataSource;
    
    private static final int CHUNK_SIZE = 100;
    private static final int POOL_SIZE = 5;

    @Bean
    public Job jdbcPartitioningJob() {
        return new JobBuilder("jdbcPartitioningJob", jobRepository)
                .start(masterStep())
                .build();
    }

    @Bean
    public Step masterStep() {
        return new StepBuilder("masterStep", jobRepository)
                .partitioner(slaveStep().getName(), partitioner())
                .step(slaveStep())
                .partitionHandler(partitionHandler())
                .build();
    }

    @Bean
    public Step slaveStep() {
        return new StepBuilder("slaveStep", jobRepository)
                .<Customer, Customer>chunk(CHUNK_SIZE, transactionManager)
                .reader(jdbcItemReader(null, null))
                .processor(jdbcItemProcessor())
                .writer(jdbcItemWriter())
                .build();
    }

    @Bean
    public PartitionHandler partitionHandler() {
        TaskExecutorPartitionHandler handler = new TaskExecutorPartitionHandler();
        handler.setTaskExecutor(taskExecutor());
        handler.setStep(slaveStep());
        handler.setGridSize(POOL_SIZE);
        return handler;
    }

    @Bean
    public TaskExecutor taskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(POOL_SIZE);
        executor.setMaxPoolSize(POOL_SIZE);
        executor.setThreadNamePrefix("jdbc-partition-thread-");
        executor.setWaitForTasksToCompleteOnShutdown(true);
        executor.initialize();
        return executor;
    }
}
```

### JDBC Partitioner 구현

```java
public class JdbcRangePartitioner implements Partitioner {

    @Autowired
    private DataSource dataSource;

    @Override
    public Map<String, ExecutionContext> partition(int gridSize) {
        JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource);
        
        // 최소/최대 ID 조회
        Long minId = jdbcTemplate.queryForObject("SELECT MIN(id) FROM customer", Long.class);
        Long maxId = jdbcTemplate.queryForObject("SELECT MAX(id) FROM customer", Long.class);
        
        // 파티션별 범위 계산
        long rangeSize = (maxId - minId) / gridSize + 1;
        Map<String, ExecutionContext> result = new HashMap<>();

        for (int i = 0; i < gridSize; i++) {
            ExecutionContext context = new ExecutionContext();
            
            long startId = minId + (i * rangeSize);
            long endId = (i == gridSize - 1) ? maxId : startId + rangeSize - 1;
            
            context.putLong("startId", startId);
            context.putLong("endId", endId);
            
            result.put("partition" + i, context);
        }
        
        return result;
    }
}
```

### JDBC ItemReader with Partitioning

```java
@Bean
@StepScope
public JdbcPagingItemReader<Customer> jdbcItemReader(
        @Value("#{stepExecutionContext[startId]}") Long startId,
        @Value("#{stepExecutionContext[endId]}") Long endId) {
    
    Map<String, Object> parameters = new HashMap<>();
    parameters.put("startId", startId);
    parameters.put("endId", endId);
    
    return new JdbcPagingItemReaderBuilder<Customer>()
            .name("jdbcItemReader")
            .dataSource(dataSource)
            .queryProvider(createQueryProvider())
            .parameterValues(parameters)
            .pageSize(CHUNK_SIZE)
            .rowMapper(new BeanPropertyRowMapper<>(Customer.class))
            .build();
}

private PagingQueryProvider createQueryProvider() {
    SqlPagingQueryProviderFactoryBean queryProvider = new SqlPagingQueryProviderFactoryBean();
    queryProvider.setDataSource(dataSource);
    queryProvider.setSelectClause("id, name, email, processed, processed_date");
    queryProvider.setFromClause("from customer");
    queryProvider.setWhereClause("where id between :startId and :endId");
    
    Map<String, Order> sortKeys = new HashMap<>();
    sortKeys.put("id", Order.ASCENDING);
    queryProvider.setSortKeys(sortKeys);
    
    try {
        return queryProvider.getObject();
    } catch (Exception e) {
        throw new RuntimeException(e);
    }
}

@Bean
public ItemProcessor<Customer, Customer> jdbcItemProcessor() {
    return customer -> {
        customer.setProcessed(true);
        customer.setProcessedDate(LocalDateTime.now());
        return customer;
    };
}

@Bean
public JdbcBatchItemWriter<Customer> jdbcItemWriter() {
    return new JdbcBatchItemWriterBuilder<Customer>()
            .dataSource(dataSource)
            .sql("UPDATE customer SET processed = :processed, processed_date = :processedDate WHERE id = :id")
            .beanMapped()
            .build();
}
```

---

## MyBatis 버전 파티셔닝

### 기본 구성

```java
@Configuration
@EnableBatchProcessing
public class MyBatisPartitioningJobConfig {

    @Autowired
    private JobRepository jobRepository;
    
    @Autowired
    private PlatformTransactionManager transactionManager;
    
    @Autowired
    private SqlSessionTemplate sqlSessionTemplate;
    
    private static final int CHUNK_SIZE = 100;
    private static final int POOL_SIZE = 5;

    @Bean
    public Job myBatisPartitioningJob() {
        return new JobBuilder("myBatisPartitioningJob", jobRepository)
                .start(masterStep())
                .build();
    }

    @Bean
    public Step masterStep() {
        return new StepBuilder("masterStep", jobRepository)
                .partitioner(slaveStep().getName(), partitioner())
                .step(slaveStep())
                .partitionHandler(partitionHandler())
                .build();
    }

    @Bean
    public Step slaveStep() {
        return new StepBuilder("slaveStep", jobRepository)
                .<Customer, Customer>chunk(CHUNK_SIZE, transactionManager)
                .reader(myBatisItemReader(null, null))
                .processor(myBatisItemProcessor())
                .writer(myBatisItemWriter())
                .build();
    }

    @Bean
    public PartitionHandler partitionHandler() {
        TaskExecutorPartitionHandler handler = new TaskExecutorPartitionHandler();
        handler.setTaskExecutor(taskExecutor());
        handler.setStep(slaveStep());
        handler.setGridSize(POOL_SIZE);
        return handler;
    }

    @Bean
    public TaskExecutor taskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(POOL_SIZE);
        executor.setMaxPoolSize(POOL_SIZE);
        executor.setThreadNamePrefix("mybatis-partition-thread-");
        executor.setWaitForTasksToCompleteOnShutdown(true);
        executor.initialize();
        return executor;
    }
}
```

### MyBatis Partitioner 구현

```java
public class MyBatisRangePartitioner implements Partitioner {

    @Autowired
    private SqlSessionTemplate sqlSessionTemplate;

    @Override
    public Map<String, ExecutionContext> partition(int gridSize) {
        // 최소/최대 ID 조회
        Long minId = sqlSessionTemplate.selectOne("customer.selectMinId");
        Long maxId = sqlSessionTemplate.selectOne("customer.selectMaxId");
        
        // 파티션별 범위 계산
        long rangeSize = (maxId - minId) / gridSize + 1;
        Map<String, ExecutionContext> result = new HashMap<>();

        for (int i = 0; i < gridSize; i++) {
            ExecutionContext context = new ExecutionContext();
            
            long startId = minId + (i * rangeSize);
            long endId = (i == gridSize - 1) ? maxId : startId + rangeSize - 1;
            
            context.putLong("startId", startId);
            context.putLong("endId", endId);
            
            result.put("partition" + i, context);
        }
        
        return result;
    }
}
```

### MyBatis ItemReader with Partitioning

```java
@Bean
@StepScope
public MyBatisPagingItemReader<Customer> myBatisItemReader(
        @Value("#{stepExecutionContext[startId]}") Long startId,
        @Value("#{stepExecutionContext[endId]}") Long endId) {
    
    Map<String, Object> parameters = new HashMap<>();
    parameters.put("startId", startId);
    parameters.put("endId", endId);
    
    return new MyBatisPagingItemReaderBuilder<Customer>()
            .sqlSessionFactory(sqlSessionTemplate.getSqlSessionFactory())
            .queryId("customer.selectCustomersByRange")
            .parameterValues(parameters)
            .pageSize(CHUNK_SIZE)
            .build();
}

@Bean
public ItemProcessor<Customer, Customer> myBatisItemProcessor() {
    return customer -> {
        customer.setProcessed(true);
        customer.setProcessedDate(LocalDateTime.now());
        return customer;
    };
}

@Bean
public MyBatisBatchItemWriter<Customer> myBatisItemWriter() {
    return new MyBatisBatchItemWriterBuilder<Customer>()
            .sqlSessionFactory(sqlSessionTemplate.getSqlSessionFactory())
            .statementId("customer.updateCustomer")
            .build();
}
```

### MyBatis Mapper XML

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
        "https://mybatis.org/dtd/mybatis-3-mapper.dtd">

<mapper namespace="customer">
    
    <select id="selectMinId" resultType="java.lang.Long">
        SELECT MIN(id) FROM customer
    </select>
    
    <select id="selectMaxId" resultType="java.lang.Long">
        SELECT MAX(id) FROM customer
    </select>
    
    <select id="selectCustomersByRange" parameterType="map" resultType="Customer">
        SELECT id, name, email, processed, processed_date
        FROM customer 
        WHERE id BETWEEN #{startId} AND #{endId}
        ORDER BY id ASC
        LIMIT #{_skiprows}, #{_pagesize}
    </select>
    
    <update id="updateCustomer" parameterType="Customer">
        UPDATE customer 
        SET processed = #{processed}, 
            processed_date = #{processedDate}
        WHERE id = #{id}
    </update>
    
</mapper>
```

---

## 파티셔닝 모니터링 및 성능 최적화

### 1. 파티션 상태 모니터링

```java
@Component
public class PartitioningJobListener implements JobExecutionListener {

    private static final Logger logger = LoggerFactory.getLogger(PartitioningJobListener.class);

    @Override
    public void beforeJob(JobExecution jobExecution) {
        logger.info("파티셔닝 Job 시작: {}", jobExecution.getJobInstance().getJobName());
    }

    @Override
    public void afterJob(JobExecution jobExecution) {
        Collection<StepExecution> stepExecutions = jobExecution.getStepExecutions();
        
        for (StepExecution stepExecution : stepExecutions) {
            if (stepExecution.getStepName().equals("masterStep")) {
                Collection<StepExecution> partitionStepExecutions = stepExecution.getStepExecutions();
                
                logger.info("총 파티션 수: {}", partitionStepExecutions.size());
                
                for (StepExecution partitionExecution : partitionStepExecutions) {
                    logger.info("파티션: {}, 읽은 아이템: {}, 처리한 아이템: {}, 쓴 아이템: {}, 실행시간: {}ms",
                        partitionExecution.getStepName(),
                        partitionExecution.getReadCount(),
                        partitionExecution.getFilterCount(),
                        partitionExecution.getWriteCount(),
                        partitionExecution.getEndTime().getTime() - partitionExecution.getStartTime().getTime());
                }
            }
        }
        
        logger.info("파티셔닝 Job 완료: {}, 상태: {}", 
            jobExecution.getJobInstance().getJobName(), 
            jobExecution.getStatus());
    }
}
```

### 2. 동적 파티션 크기 조정

```java
public class DynamicPartitioner implements Partitioner {

    @Autowired
    private DataSource dataSource;
    
    @Value("${batch.partition.target-size:10000}")
    private int targetPartitionSize;

    @Override
    public Map<String, ExecutionContext> partition(int gridSize) {
        JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource);
        
        Long totalCount = jdbcTemplate.queryForObject("SELECT COUNT(*) FROM customer", Long.class);
        
        // 데이터 크기에 따라 동적으로 파티션 수 조정
        int optimalGridSize = Math.max(1, (int) Math.ceil((double) totalCount / targetPartitionSize));
        optimalGridSize = Math.min(optimalGridSize, gridSize); // 최대 gridSize로 제한
        
        Long minId = jdbcTemplate.queryForObject("SELECT MIN(id) FROM customer", Long.class);
        Long maxId = jdbcTemplate.queryForObject("SELECT MAX(id) FROM customer", Long.class);
        
        long rangeSize = (maxId - minId) / optimalGridSize + 1;
        Map<String, ExecutionContext> result = new HashMap<>();

        for (int i = 0; i < optimalGridSize; i++) {
            ExecutionContext context = new ExecutionContext();
            
            long startId = minId + (i * rangeSize);
            long endId = (i == optimalGridSize - 1) ? maxId : startId + rangeSize - 1;
            
            context.putLong("startId", startId);
            context.putLong("endId", endId);
            
            result.put("partition" + i, context);
        }
        
        return result;
    }
}
```

### 3. 파티셔닝 최적화 팁

#### 성능 최적화 권장사항

1. **적절한 파티션 크기**
   - 파티션당 10,000~50,000건 정도가 적절
   - 너무 작으면 오버헤드 증가, 너무 크면 병렬화 효과 감소

2. **인덱스 활용**
   - 파티션 키(보통 ID)에 인덱스 필수
   - WHERE 조건에 사용되는 컬럼들도 인덱스 고려

3. **스레드 풀 크기 조정**
   - CPU 코어 수의 2배 정도로 설정
   - DB 커넥션 풀 크기도 함께 고려

4. **메모리 관리**
   - 각 파티션별로 독립적인 메모리 사용
   - Chunk Size * 파티션 수 * 객체 크기 고려

```java
// 성능 최적화된 설정 예시
@Bean
public TaskExecutor optimizedTaskExecutor() {
    ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
    
    // CPU 코어 수 기반 설정
    int coreCount = Runtime.getRuntime().availableProcessors();
    executor.setCorePoolSize(coreCount);
    executor.setMaxPoolSize(coreCount * 2);
    executor.setQueueCapacity(100);
    
    // 스레드 이름 및 대기 설정
    executor.setThreadNamePrefix("optimized-partition-");
    executor.setWaitForTasksToCompleteOnShutdown(true);
    executor.setAwaitTerminationSeconds(60);
    
    // 거부 정책 설정
    executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
    
    executor.initialize();
    return executor;
}
```

---

## 주의사항 및 제한사항

### 1. 트랜잭션 격리
- 각 파티션은 독립적인 트랜잭션으로 실행
- 파티션 간 데이터 일관성은 애플리케이션에서 보장해야 함

### 2. 데이터 중복 처리 방지
- 파티션 범위가 겹치지 않도록 주의
- ID 기반 파티셔닝 시 범위 계산 정확성 중요

### 3. 에러 처리
- 일부 파티션 실패 시 전체 Job은 실패로 처리
- Skip, Retry 정책은 각 파티션별로 독립적으로 적용

### 4. 데이터베이스 부하
- 동시 실행되는 파티션 수만큼 DB 커넥션 사용
- DB 부하 및 Lock 경합 고려 필요

```java
// 에러 처리 및 재시도 설정 예시
@Bean
public Step resilientSlaveStep() {
    return new StepBuilder("resilientSlaveStep", jobRepository)
            .<Customer, Customer>chunk(CHUNK_SIZE, transactionManager)
            .reader(itemReader())
            .processor(itemProcessor())
            .writer(itemWriter())
            .faultTolerant()
            .skipLimit(100)
            .skip(Exception.class)
            .retryLimit(3)
            .retry(Exception.class)
            .build();
}
```